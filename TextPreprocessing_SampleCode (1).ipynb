{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wcWymkcXVo6T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: emoji in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (2.8.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from click->nltk) (0.4.6)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: spacy in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (3.7.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (1.21.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (8.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (4.64.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (0.3.3)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (63.4.1)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (2.4.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.8.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.10.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "#!pip install contractions\n",
    "!pip install emoji\n",
    "!pip install nltk\n",
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6qPLzgywWQ7R"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "#import statistics\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OIgyMGv6WSnL",
    "outputId": "1bfd453f-06cf-4532-e8d7-dd163d180c9c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Error loading whitespace: Package 'whitespace' not found\n",
      "[nltk_data]     in index\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('whitespace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "CH1TWJn9WUsJ"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "import emoji\n",
    "import regex\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "6wHL97gOWWQh",
    "outputId": "7930640d-a179-438d-a323-9a24d2f00c62"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>task1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1123757263427186690</td>\n",
       "      <td>hate wen females hit ah nigga with tht bro ðŸ˜‚ðŸ˜‚,...</td>\n",
       "      <td>HOF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1123733301397733380</td>\n",
       "      <td>RT @airjunebug: When you're from the Bay but y...</td>\n",
       "      <td>HOF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1123734094108659712</td>\n",
       "      <td>RT @DonaldJTrumpJr: Dear Democrats: The Americ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1126951188170199049</td>\n",
       "      <td>RT @SheLoveTimothy: He ainâ€™t on drugs he just ...</td>\n",
       "      <td>HOF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1126863510447710208</td>\n",
       "      <td>RT @TavianJordan: Summer â€˜19 Iâ€™m coming for yo...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1126798721025544193</td>\n",
       "      <td>RT @prodnose: Good morning, everyone.\\nFollowi...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1126833089190219777</td>\n",
       "      <td>@cheezitking123 this what you get for tryna ge...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1130037092845670400</td>\n",
       "      <td>earphones ko ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1127028455651123201</td>\n",
       "      <td>RT @nj_linguist: @realgonegirl @elivalley I th...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1130285076858789889</td>\n",
       "      <td>iâ€™m tired as fuck. and man, physically ainâ€™t S...</td>\n",
       "      <td>HOF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                tweet_id                                               text  \\\n",
       "0    1123757263427186690  hate wen females hit ah nigga with tht bro ðŸ˜‚ðŸ˜‚,...   \n",
       "1    1123733301397733380  RT @airjunebug: When you're from the Bay but y...   \n",
       "2    1123734094108659712  RT @DonaldJTrumpJr: Dear Democrats: The Americ...   \n",
       "3    1126951188170199049  RT @SheLoveTimothy: He ainâ€™t on drugs he just ...   \n",
       "4    1126863510447710208  RT @TavianJordan: Summer â€˜19 Iâ€™m coming for yo...   \n",
       "..                   ...                                                ...   \n",
       "995  1126798721025544193  RT @prodnose: Good morning, everyone.\\nFollowi...   \n",
       "996  1126833089190219777  @cheezitking123 this what you get for tryna ge...   \n",
       "997  1130037092845670400                               earphones ko ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­   \n",
       "998  1127028455651123201  RT @nj_linguist: @realgonegirl @elivalley I th...   \n",
       "999  1130285076858789889  iâ€™m tired as fuck. and man, physically ainâ€™t S...   \n",
       "\n",
       "    task1  \n",
       "0     HOF  \n",
       "1     HOF  \n",
       "2     NOT  \n",
       "3     HOF  \n",
       "4     NOT  \n",
       "..    ...  \n",
       "995   NOT  \n",
       "996   NOT  \n",
       "997   NOT  \n",
       "998   NOT  \n",
       "999   HOF  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft=pd.read_csv(\"sample_text - Sheet1 (1).csv\")\n",
    "dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "isWPYmLkWYWp",
    "outputId": "1a3b4a15-7f69-477e-860a-749e38fc16ef"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>task1</th>\n",
       "      <th>Text_Tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1123757263427186690</td>\n",
       "      <td>hate wen females hit ah nigga with tht bro ðŸ˜‚ðŸ˜‚,...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>[hate, wen, females, hit, ah, nigga, with, tht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1123733301397733380</td>\n",
       "      <td>RT @airjunebug: When you're from the Bay but y...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>[rt, @, airjunebug, :, when, you, 're, from, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1123734094108659712</td>\n",
       "      <td>RT @DonaldJTrumpJr: Dear Democrats: The Americ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>[rt, @, donaldjtrumpjr, :, dear, democrats, :,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1126951188170199049</td>\n",
       "      <td>RT @SheLoveTimothy: He ainâ€™t on drugs he just ...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>[rt, @, shelovetimothy, :, he, ain, â€™, t, on, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1126863510447710208</td>\n",
       "      <td>RT @TavianJordan: Summer â€˜19 Iâ€™m coming for yo...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>[rt, @, tavianjordan, :, summer, â€˜, 19, i, â€™, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1126798721025544193</td>\n",
       "      <td>RT @prodnose: Good morning, everyone.\\nFollowi...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>[rt, @, prodnose, :, good, morning, ,, everyon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1126833089190219777</td>\n",
       "      <td>@cheezitking123 this what you get for tryna ge...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>[@, cheezitking123, this, what, you, get, for,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1130037092845670400</td>\n",
       "      <td>earphones ko ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­</td>\n",
       "      <td>NOT</td>\n",
       "      <td>[earphones, ko, ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1127028455651123201</td>\n",
       "      <td>RT @nj_linguist: @realgonegirl @elivalley I th...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>[rt, @, nj_linguist, :, @, realgonegirl, @, el...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1130285076858789889</td>\n",
       "      <td>iâ€™m tired as fuck. and man, physically ainâ€™t S...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>[i, â€™, m, tired, as, fuck, ., and, man, ,, phy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                tweet_id                                               text  \\\n",
       "0    1123757263427186690  hate wen females hit ah nigga with tht bro ðŸ˜‚ðŸ˜‚,...   \n",
       "1    1123733301397733380  RT @airjunebug: When you're from the Bay but y...   \n",
       "2    1123734094108659712  RT @DonaldJTrumpJr: Dear Democrats: The Americ...   \n",
       "3    1126951188170199049  RT @SheLoveTimothy: He ainâ€™t on drugs he just ...   \n",
       "4    1126863510447710208  RT @TavianJordan: Summer â€˜19 Iâ€™m coming for yo...   \n",
       "..                   ...                                                ...   \n",
       "995  1126798721025544193  RT @prodnose: Good morning, everyone.\\nFollowi...   \n",
       "996  1126833089190219777  @cheezitking123 this what you get for tryna ge...   \n",
       "997  1130037092845670400                               earphones ko ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­   \n",
       "998  1127028455651123201  RT @nj_linguist: @realgonegirl @elivalley I th...   \n",
       "999  1130285076858789889  iâ€™m tired as fuck. and man, physically ainâ€™t S...   \n",
       "\n",
       "    task1                                     Text_Tokenized  \n",
       "0     HOF  [hate, wen, females, hit, ah, nigga, with, tht...  \n",
       "1     HOF  [rt, @, airjunebug, :, when, you, 're, from, t...  \n",
       "2     NOT  [rt, @, donaldjtrumpjr, :, dear, democrats, :,...  \n",
       "3     HOF  [rt, @, shelovetimothy, :, he, ain, â€™, t, on, ...  \n",
       "4     NOT  [rt, @, tavianjordan, :, summer, â€˜, 19, i, â€™, ...  \n",
       "..    ...                                                ...  \n",
       "995   NOT  [rt, @, prodnose, :, good, morning, ,, everyon...  \n",
       "996   NOT  [@, cheezitking123, this, what, you, get, for,...  \n",
       "997   NOT                           [earphones, ko, ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­]  \n",
       "998   NOT  [rt, @, nj_linguist, :, @, realgonegirl, @, el...  \n",
       "999   HOF  [i, â€™, m, tired, as, fuck, ., and, man, ,, phy...  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft['Text_Tokenized'] = dft['text'].str.lower().apply(word_tokenize)\n",
    "dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "RmANNgOrWa7j"
   },
   "outputs": [],
   "source": [
    "#Preprocessing\n",
    "ps =PorterStemmer()\n",
    "lemmatiser = WordNetLemmatizer()\n",
    "english_stopwords = stopwords.words('english')\n",
    "exclude = set(string.punctuation)\n",
    "text=dft['text']\n",
    "\n",
    "def preprocess(text):\n",
    "  #text = contractions.fix(text.lower(), slang=True)\n",
    "    text=text.lower()\n",
    "    text= re.sub(r'\\d+', '', text)\n",
    "    text=re.sub(r'$', '', text)\n",
    "    text=re.sub('<.*?>','',text)\n",
    "  #text=re.sub(r'\\W*\\b\\w{1,3}\\b')\n",
    "    text=re.sub(r'http\\S+', '', text)\n",
    "    text = text.encode(\"ascii\", \"ignore\")\n",
    "    text = text.decode()\n",
    "  #text=re.sub(r\"[\\\\p{Cf}]\", \"\",text)\n",
    "    text = ''.join(ch for ch in text if ch not in exclude)\n",
    "    tokens = word_tokenize(text)\n",
    "  #print(\"Tokens:\", tokens)\n",
    "  #tokens = [lemmatiser.lemmatize(t) for t in tokens]\n",
    "  #tokens=[ps.stem(t) for t in tokens]\n",
    "    tokens = [t for t in tokens if t not in english_stopwords]\n",
    "    tokens = [t for t in tokens if len(t) > 2]\n",
    "    text = \" \".join(tokens)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y5A7whUfWcni",
    "outputId": "5ccd9b5a-8257-438c-a936-89b99a84f433"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    hate wen females hit nigga tht bro tryna make ...\n",
       "1    airjunebug youre bay youre really nigga heart ...\n",
       "2    donaldjtrumpjr dear democrats american people ...\n",
       "3           shelovetimothy aint drugs bored shit bored\n",
       "4    tavianjordan summer coming boring shit beach d...\n",
       "5                                hermescxbin turn shit\n",
       "6    spaceboykenny know fuck bout cel shading horny...\n",
       "7    polo ones thats feeeling fly fly like bitch do...\n",
       "8                                    fucking love life\n",
       "9              nigbmt newspaper weak bro ending pissed\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_data=dft['text'][:10].apply(lambda X: preprocess(X))\n",
    "pre_data"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
